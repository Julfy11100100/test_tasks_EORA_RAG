# Тестовый проект по обработке и поиску информации

Данный репозиторий содержит тестовый проект, разработанный в рамках тестового задания.

## Алгоритм работы

### 1. Парсинг источников  
Проект начинается с обработки списка ссылок. Для сбора информации используется собственный парсер `HTMLParser`.

### 2. Формирование семантических чанков  
Собранные данные разбиваются на текстовые сегменты с помощью модуля `ContentChunker` для более удобной обработки.

### 3. Векторизация и сохранение  
Каждый текстовый сегмент преобразуется в векторное представление (embedding) через сервис `EmbeddingService` и добавляется в базу данных векторных представлений `ChromaDB`.

### 4. Сервер для обработки пользовательских запросов  
Реализовано web-приложение на FastAPI, принимающее вопросы пользователей, связанные с содержимым сайтов.

### 5. Поиск релевантной информации и генерация ответов  
С помощью `SearchService` определяется наиболее релевантная информация из базы. Модуль `ResponseGenerator` формирует на её основе развернутый ответ. Для генерации используются две языковые модели (`LLM`): `sonar` и `GigaChat`. Выбор модели осуществляется через параметр `LLM_PROVIDER` в `config.py`.

---

## Технологии и компоненты

- Python
- FastAPI
- BeautifulSoup
- Векторные представления с использованием SentenceTransformer и ChromaDB
- LLM-модели: sonar и GigaChat

---

## Запуск проекта

1. Клонируйте репозиторий  
2. Установите зависимости из `requirements.txt`  
3. Создайте `.env` файл на основе `.env.example`. Вставьте свои креды, такие как `GIGACHAT_API_KEY` и `SONAR_API_KEY`
4. Запустите скрипт scripts/init_database.py для создания vector_db. (ChromaDB c эмбеддингами информации по сайту)
5. Запустите сервер FastAPI (например, через `uvicorn app.main:app --host 0.0.0.0 --port 8000` либо `app/main.py`)  
6. Отправляйте запросы к API с вопросами по содержимому сайтов на эндпоинт `/ask` (удобнее всего через Swagger — `0.0.0.0:8000/docs`)

---

## Далее информация по тестовому заданию

### Что пробовали сделать?  
Помимо `Sonar` и `GigaChat`, попытался генерировать ответы через другие модели, например — Amvera LLM с моделями `llama8b` и `llama70b`.  
Перепробовал кучу разных промтов, настроек модели, таких как `temperature`, `max_tokens`.  

### Что сработало, а что не очень?  
В ходе работы с `GigaChat` выяснилось, что у `GigaChat API` очень строгий фильтр цензуры, и промты, которые срабатывали на сайте, по API выдавали стандартный ответ по типу:  

> "Генеративные языковые модели не обладают собственным мнением – их ответы являются обобщением информации, находящейся в открытом доступе. Чтобы избежать ошибок и неправильного толкования, разговоры на чувствительные темы могут быть ограничены."

В итоге остановился на `Sonar` (благо нашел аккаунт с Perplexity Pro, и у них есть 5$ со старта на токены). Но и тут пришлось повозиться с промтами и настройками. Основная проблема была в том, что модель, несмотря на прописанные запреты, находила какие-то ссылки вне контекста.

### Как оценили качество решения?  
На мой взгляд — поставленная задача выполнена. Возможно, упустил какие-то детали, так как ранее не работал с RAG.

### Что бы ещё добавили в решение, если бы было больше времени?
- Обработать кейсы, при которых LLM не выдаёт корректный ответ, возможно подключать более мощную модель на такие кейсы.
- Реализовать Telegram-бота.  
- Доработать парсер.  
- Попробовать другие LLM модели.  
- Покрыть код тестами.
---

## Вопросы и ответы

### Вопрос: Какие решения EORA предлагала для автоматизации контакт-центров?  
**Ответ:**  
EORA предлагала решения для автоматизации контакт-центров на базе чат-ботов и голосовых ассистентов, которые отвечают на вопросы клиентов, помогают операторам и интегрируются с внутренними системами заказчиков.

Примеры:  
- Бот-справочник для контакт-центра энергокомпании ICL, работающий на платформе zDialog и интегрированный с программой заказчика.  
  https://eora.ru/cases/icl-bot-sufler-dlya-kontakt-centra  
- Пилотный проект автоматизации контакт-центра «Додо Пиццы» с голосовым ботом, который обрабатывает звонки, понимает речь клиентов и взаимодействует с информационной системой Dodo IS.  
  https://eora.ru/cases/dodo-pizza-pilot-po-avtomatizacii-kontakt-centra

---

### Вопрос: Какие технологии используются EORA для компьютерного зрения?  
**Ответ:**  
EORA использует нейросетевые модели для компьютерного зрения, включая сегментацию кадров видео с выделением человека, генеративно-состязательные сети (GAN) для обнаружения аномалий и комплексные модели для обработки видеопотоков с сегментацией частей тела и объектов. Эти модели адаптированы для работы на мобильных устройствах и в облаке, обеспечивая разные уровни точности и производительности.

Примеры:  
- Нейросеть для сегментации человека на видео с тремя моделями для разных мобильных устройств, позволяющая менять фон и накладывать маски в приложении для обработки фото и видео.  
  https://eora.ru/cases/nejroset-segmentaciya-video  
- Система обнаружения посторонних предметов на днищах автомобилей с использованием GAN, адаптированная под специфические данные заказчика, с точностью 0.73.  
  https://eora.ru/cases/computer-vision/iss-analiz-foto-avtomobilej

---

### Вопрос: Что вы можете сделать для ритейлеров?  
**Ответ:**  
Для ритейлеров EORA может разработать чат-боты и голосовые ассистенты, интегрированные в мессенджеры и голосовые экосистемы, которые упрощают взаимодействие с клиентами и автоматизируют процессы покупки и оплаты.

Например, реализован бот для бесконтактной покупки питания через WhatsApp, который позволяет офисным работникам выбирать еду, оплачивать её и получать уведомления, а также интегрируется с эквайрингом и базами данных.  
https://eora.ru/cases/workeat-whatsapp-bot

Другой пример — навык для проверки лотерейных билетов в Алисе, который помогает пользователям быстро проверить билеты, получить ответы на вопросы и найти точки выдачи призов, что демонстрирует опыт создания удобных голосовых сервисов для ритейла и развлечений.  
https://eora.ru/cases/navyki-dlya-golosovyh-assistentov/navyk-dlya-proverki-loterejnyh-biletov

